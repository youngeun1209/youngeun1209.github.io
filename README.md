# Young-Eun Lee

## Introduction
<img src="/images/Young.jpg" align="right" width="20%" height="20%">

Young-Eun Lee
* PhD Candidate at Pattern Recognition & Machine Learning Lab 

in Korea University

Email: ye_lee@koea.ac.kr

<a href="https://scholar.google.co.kr/citations?user=fCkoUvEAAAAJ">Google Scholar</a>

<a href="https://youngeun1209.github.io">Homepage</a>

<a href="https://github.com/youngeun1209">GitHub</a>

## Publication
### Journals
* J.-H. Jeong, J.-H. Cho, <b>Y.-E. Lee</b>, S.-H. Lee, G.-H. Shin, Y.-S. Kweon, J. R. Millán, K.-R. Müller, and S.-W. Lee, "2020 International Brain-Computer Interface Competition: A Review," Frontiers in Human Neuroscience, Vol. 16, 2022, pp. 898300. 
* <b>Y.-E. Lee</b>, G.-H. Shin, M. Lee, and S.-W. Lee, "Mobile BCI dataset of scalp- and ear-EEGs with ERP and SSVEP paradigms while standing, walking, and running," Scientific Data, Vol. 8, No. 315, 2021.
* <b>Y.-E. Lee</b>, N.-S. Kwak, S.-W. Lee, "A Real-time movement artifact removal method for ambulatory brain-computer interfaces," IEEE Trans. on Neural Systems & Rehabilitation Engineering, Vol. 28, No.12, 2020, pp. 2660-2670. 
* M.-H. Lee, O.-Y. Kwon, Y.-J. Kim, H.-K. Kim, <b>Y.-E. Lee</b>, J. Williamson, S. Fazli, and S.-W. Lee, "EEG Dataset and OpenBMI Toolbox for Three BCI Paradigms: An Investigation into BCI Illiteracy," GigaScience, Vol. 8, No. 5, 2019, pp. 1-16.
* M.-H. Lee, J. Williamson, <b>Y.-E. Lee</b>, and S.-W. Lee, "Mental Fatigue in Central and Peripheral Field SSVEP and Its Effects on ERP Responses," NeuroReport, Vol. 29, 2018, pp. 1301-1308.
* Y.-E. Lee, H. M. Husin, M.-P. Forte, S.-W. Lee, and K. J. Kuchenbecker, “Learning to Estimate Palpation Forces in Robotic Surgery from Visual-Inertial Data,” IEEE Transactions on Medical Robotics and Bionics. (Under review)
* J.-H. Jeong, J.-H. Cho, K.-H. Shim, <b>Y.-E. Lee</b>, and S.-W. Lee, “NeuroBoT: Short-Term Brain-Machine Learning of Real-Time EEG Decoding for BMI-of-Things,” IEEE Transactions on Systems Man and Cybernetics: Systems. (Under review)

### Conferences
* <b>Y.-E. Lee</b>, S.-H. Lee, S. Kim, S.-H. Kim, J.-S. Lee, and S.-W. Lee, “Speech Synthesis from Brain Signals Based on Generative Model,” Proc. 11th IEEE International Winter Conference on Brain-Computer Interface, Feb. 20-22, 2023.
* S. Kim, J.-W. Lee, <b>Y.-E. Lee</b>, S.-H. Lee, “Subject-Independent Classification of Brain Signals using Skip Connections,” Proc. 11th IEEE International Winter Conference on Brain-Computer Interface, Feb. 20-22, 2023.
* S.-H. Lee, <b>Y.-E. Lee</b>, S. Kim, S.-W. Lee, “Towards Neural Decoding of Imagined Speech based on Spoken Speech,” Proc. 11th IEEE International Winter Conference on Brain-Computer Interface, Feb. 20-22, 2023.
* <b>Y.-E. Lee</b>, S.-H. Lee, S.-H Kim, and S.-W. Lee, "Towards Voice Reconstruction from EEG during Imagined Speech," AAAI Conference on Artificial Intelligence (AAAI), 2023.
* <b>Y.-E. Lee</b> and S.-H. Lee, "EEG-Transformer: Self-attention from Transformer Architecture for Decoding EEG of Imagined Speech," Proc. 10th IEEE International Winter Conference on Brain-Computer Interface, Feb. 21-23, 2022.
* S.-H. Lee, <b>Y.-E. Lee</b> and S.-W. Lee, "Toward Imagined Speech based Smart Communication System: Potential Applications on Metaverse Conditions," Proc. 10th IEEE International Winter Conference on Brain-Computer Interface, Feb. 21-23, 2022.
* <b>Y.-E. Lee</b> and S.-W. Lee, “Decoding event-related potential from ear-EEG signals based on ensemble convolutional neural networks in ambulatory environment,” Proc. 9th IEEE International Winter Conference on Brain-Computer Interface, Feb. 22-24, 2021.
* S.-H. Lee&#42;, <b>Y.-E. Lee</b>&#42;, S.-W. Lee, “Voice of your brain: Cognitive representations of imagined speech, overt speech, and speech  perception based on EEG,” Arxiv preprint, 2021.
* <b>Y.-E. Lee</b> and M. Lee, “Decoding visual responses based on deep neural networks with ear-EEG signals,” Proc. 8th IEEE International Winter Conference on Brain-Computer Interface, Feb. 26-28, 2020.
* <b>Y.-E. Lee</b>, M. Lee, S.-W. Lee, “Reconstructing ERP signals using generative adversarial networks for mobile brain-machine interface,” Arxiv preprint, 2020.
* <b>Y.-E. Lee</b>, H. M. Husin, M. P. Forte, S.-W. Lee, K. J. Kuchenbecker, “Vision-based Force Estimation for a da Vinci Instrument Using Deep Neural Networks,” SAGES, 2020.


## Patents
* “User Authentication Apparatus and Method Using Brainwave Signal According to Imagined Speech,” Application Number: US 17/884,870 (U.S.A).
* “Apparatus and Method for Left- and Right-Foot Classification Based on Brain Signals,” Registration Number: 10-2276991 (Korea).
* “Method and apparatus for speech synthesis based on brain signals during imagined speech,” Application Number: 10-2022-0173551 (Korea).
* “Smart Home Control System and Apparatus based on Brain-Computer Interface Using Minimum Stimulus,” Application Number: 10-2022-0163784 (Korea).
* “A method for user intent recognition through similarity comparison by extracting features from imagined speech and overt speech in brain-computer interface,” Application Number: 10-2022-0163782 (Korea).
* “Brain-Computer Interface System for Supporting New Language Acquisition Using Brain Signals,” Application Number: 10-2022-0173553 (Korea).
* “Bio-signal-based metaverse system implementation method for predicting and reconstructing user's facial emotions and mouth shapes based on bio-signals,” Application Number: 10-2022-0163781 (Korea).
* “Personal authentication apparatus and system based on brain signals of imagined speech,” Application Number: 10-2021-0079992 (Korea).
* “Apparatus and method for left- and right-foot classification based on brain signals,” Application Number: 10-2018-0135194 (Korea).

## Career
* Visiting Researcher at <b>Max-Planck Institute (MPI)</b> for Intelligent Systems, 2019.08.01 - 2020.01.31.
* Intern at <b>IBM</b> Korea Watson, 2016.07.01 - 2016.09.30.

고려대학교 뇌공학과 이영은
