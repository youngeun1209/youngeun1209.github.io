# <a href="https://youngeun1209.github.io">Young-Eun Lee</a>

## Introduction
<img src="/images/Young.jpg" align="right" width="20%" height="20%">

Young-Eun Lee
* Post Doctoral Researcher at Stanford University

## Career
* Post-Doc at Dept. Psychiatry and Behavioral Sciences, Stanford University, USA, Nov. 2024 - Present
* Post-Doc at Dept. Artificial Intelligence, Korea University, Korea, Mar.2024 - Oct.2024
* Visiting Researcher at Max-Planck Institute for Intelligent Systems, Germany, Aug.2019 - Jan.2020
* Intern at Watson team at IBM Korea, Korea, Jul.2016 - Sep.2016

## Education
* Ph.D. at Dept. Brain and Cognitive Engineering, Korea University, Korea, Sep.2017 - Feb.2024
  -	Supervisor: Seong-Whan Lee (Distinguished Professor at Korea University)
* B.S. at Electronic & Mechanical Engineering, Handong Global University, Korea, Mar.2012 - Aug.2016

Email: youngeun at stanford dot edu

<a href="https://scholar.google.co.kr/citations?user=fCkoUvEAAAAJ">Google Scholar</a>

<a href="https://github.com/youngeun1209">GitHub</a>

<a href="https://www.linkedin.com/in/young-eun-lee-bci">Linked In</a>

## Selected Paper
* <b>Y.-E. Lee</b>, S.-H. Lee, S.-H Kim, and S.-W. Lee, "Towards Voice Reconstruction from EEG during Imagined Speech," AAAI Conference on Artificial Intelligence (AAAI), 2023.
* <b>Y.-E. Lee</b>, N.-S. Kwak, S.-W. Lee, "A Real-time movement artifact removal method for ambulatory brain-computer interfaces," IEEE Trans. on Neural Systems & Rehabilitation Engineering, Vol. 28, No.12, 2020, pp. 2660-2670.
* <b>Y.-E. Lee</b>, H. M. Husin, M.-P. Forte, S.-W. Lee, and K. J. Kuchenbecker, “Learning to Estimate Palpation Forces in Robotic Surgery from Visual-Inertial Data,” IEEE Transactions on Medical Robotics and Bionics, Vol. 5, No. 3, 2023, pp. 496-506.
* M.-H. Lee, O.-Y. Kwon, Y.-J. Kim, H.-K. Kim, <b>Y.-E. Lee</b>, J. Williamson, S. Fazli, and S.-W. Lee, "EEG Dataset and OpenBMI Toolbox for Three BCI Paradigms: An Investigation into BCI Illiteracy," GigaScience, Vol. 8, No. 5, 2019, pp. 1-16.

## Publication
### International Journals
* <b>Y.-E. Lee</b>, H. M. Husin, M.-P. Forte, S.-W. Lee, and K. J. Kuchenbecker, “Learning to Estimate Palpation Forces in Robotic Surgery from Visual-Inertial Data,” IEEE Transactions on Medical Robotics and Bionics, Vol. 5, No. 3, 2023, pp. 496-506.
* J.-H. Jeong, J.-H. Cho, <b>Y.-E. Lee</b>, S.-H. Lee, G.-H. Shin, Y.-S. Kweon, J. R. Millán, K.-R. Müller, and S.-W. Lee, "2020 International Brain-Computer Interface Competition: A Review," Frontiers in Human Neuroscience, Vol. 16, 2022, pp. 898300. 
* <b>Y.-E. Lee</b>, G.-H. Shin, M. Lee, and S.-W. Lee, "Mobile BCI dataset of scalp- and ear-EEGs with ERP and SSVEP paradigms while standing, walking, and running," Scientific Data, Vol. 8, No. 315, 2021.
* <b>Y.-E. Lee</b>, N.-S. Kwak, S.-W. Lee, "A Real-time movement artifact removal method for ambulatory brain-computer interfaces," IEEE Trans. on Neural Systems & Rehabilitation Engineering, Vol. 28, No.12, 2020, pp. 2660-2670. 
* M.-H. Lee, O.-Y. Kwon, Y.-J. Kim, H.-K. Kim, <b>Y.-E. Lee</b>, J. Williamson, S. Fazli, and S.-W. Lee, "EEG Dataset and OpenBMI Toolbox for Three BCI Paradigms: An Investigation into BCI Illiteracy," GigaScience, Vol. 8, No. 5, 2019, pp. 1-16.
* M.-H. Lee, J. Williamson, <b>Y.-E. Lee</b>, and S.-W. Lee, "Mental Fatigue in Central and Peripheral Field SSVEP and Its Effects on ERP Responses," NeuroReport, Vol. 29, 2018, pp. 1301-1308.
* J.-H. Jeong, J.-H. Cho, K.-H. Shim, <b>Y.-E. Lee</b>, and S.-W. Lee, “NeuroBoT: Short-Term Brain-Machine Learning of Real-Time EEG Decoding for BMI-of-Things,” Arxiv, 2025.
* S. J. Madsen*, <b>Y.-E. Lee*</b>, L. Q. Uddin, J. A. Mumford, D. M. Barch, D. A. Fair, I. H. Gotlib, R. A. Poldrack, A. Kuceyeski, M. Saggar, "Predicting Task Activation Maps from Resting-State Functional Connectivity using Deep Learning," bioRxiv, 2025.

### International Conferences
* D.-S. Kim, S.-H. Lee, <b>Y.-E. Lee</b>, S.-W. Lee, "Towards Speech Synthesis of Unconstrained Sentences from Speech-Related Biosignals," Proc. of EMBC, 2024.
* <b>Y.-E. Lee</b>, S.-H. Lee, S. Kim, J.-S. Lee, D.-S. Kim, S.-W. Lee, "Enhanced Generative Adversarial Networks for Unseen Word Generation from EEG Signals," Proc. of 12th IEEE International Winter Conference on Brain-Computer Interface, Feb. 26-28, 2024.
* S. Kim, S.-H. Lee, <b>Y.-E. Lee</b>, J.-W. Lee, J.-H. Park, P. Kazanzides, S.-W. Lee, "Brain-Driven Representation Learning Based on Diffusion Model," Proc. of 12th IEEE International Winter Conference on Brain-Computer Interface, Feb. 26-28, 2024.
* S.-H. Lee, <b>Y.-E. Lee</b>, S. Kim, B.-K. Ko, J.-Y. Kim, S.-W. Lee, "Neural Speech Embeddings for Speech Synthesis Based on Deep Generative Networks," Proc. of 12th IEEE International Winter Conference on Brain-Computer Interface, Feb. 26-28, 2024.
* S. Kim, <b>Y.-E. Lee</b>, S.-H. Lee, and S.-W. Lee, "Diff-E: Diffusion-based Learning for Decoding Imagined Speech EEG," Proc. of Interspeech, 2023.
* J. Lee, S.-H. Lee, <b>Y.-E. Lee</b>, S. Kim, S.-W. Lee, "Sentence Reconstruction Leveraging Contextual Meaning from Speech-Related Brain Signals," 2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC), 2023.
* <b>Y.-E. Lee</b>, S.-H. Lee, S. Kim, S.-H. Kim, J.-S. Lee, and S.-W. Lee, “Speech Synthesis from Brain Signals Based on Generative Model,” Proc. 11th IEEE International Winter Conference on Brain-Computer Interface, Feb. 20-22, 2023.
* S. Kim, J.-W. Lee, <b>Y.-E. Lee</b>, S.-H. Lee, “Subject-Independent Classification of Brain Signals using Skip Connections,” Proc. 11th IEEE International Winter Conference on Brain-Computer Interface, Feb. 20-22, 2023.
* S.-H. Lee, <b>Y.-E. Lee</b>, S. Kim, S.-W. Lee, “Towards Neural Decoding of Imagined Speech based on Spoken Speech,” Proc. 11th IEEE International Winter Conference on Brain-Computer Interface, Feb. 20-22, 2023.
* <b>Y.-E. Lee</b>, S.-H. Lee, S.-H Kim, and S.-W. Lee, "Towards Voice Reconstruction from EEG during Imagined Speech," AAAI Conference on Artificial Intelligence (AAAI), 2023.
* <b>Y.-E. Lee</b> and S.-H. Lee, "EEG-Transformer: Self-attention from Transformer Architecture for Decoding EEG of Imagined Speech," Proc. 10th IEEE International Winter Conference on Brain-Computer Interface, Feb. 21-23, 2022.
* S.-H. Lee, <b>Y.-E. Lee</b> and S.-W. Lee, "Toward Imagined Speech based Smart Communication System: Potential Applications on Metaverse Conditions," Proc. 10th IEEE International Winter Conference on Brain-Computer Interface, Feb. 21-23, 2022.
* <b>Y.-E. Lee</b> and S.-W. Lee, “Decoding event-related potential from ear-EEG signals based on ensemble convolutional neural networks in ambulatory environment,” Proc. 9th IEEE International Winter Conference on Brain-Computer Interface, Feb. 22-24, 2021.
* S.-H. Lee&#42;, <b>Y.-E. Lee</b>&#42;, S.-W. Lee, “Voice of your brain: Cognitive representations of imagined speech, overt speech, and speech  perception based on EEG,” Arxiv preprint, 2021.
* <b>Y.-E. Lee</b> and M. Lee, “Decoding visual responses based on deep neural networks with ear-EEG signals,” Proc. 8th IEEE International Winter Conference on Brain-Computer Interface, Feb. 26-28, 2020.
* <b>Y.-E. Lee</b>, M. Lee, S.-W. Lee, “Reconstructing ERP signals using generative adversarial networks for mobile brain-machine interface,” Arxiv preprint, 2020.
* <b>Y.-E. Lee</b>, H. M. Husin, M. P. Forte, S.-W. Lee, K. J. Kuchenbecker, “Vision-based Force Estimation for a da Vinci Instrument Using Deep Neural Networks,” SAGES, 2020.

### Domestic Conferences
* S. Kim, Y.-E. Lee, S.-H. Lee, S.-W. Lee, “Speech EEG classification based on residual learning for user-independent brain-computer interfaces,” Winter Symposium of the Korean Society of Brain Engineering, 2023.

## Patents
* “User Authentication Apparatus and Method Using Brainwave Signal According to Imagined Speech,” Register Number: 12,204,624, (U.S.A).
* “Method, Device and Program for Learning Artificial Neural Networks Based on Speech Imagination Biosignals and Phoneme Information,” Application Number: US 18/981,333 (U.S.A).
* "Method and Apparatus for Speech Synthesis Based on Brain Signals During Imagined Speech," Application Number: US 18/199,670 (U.S.A).
* “Brain-Computer Interface System for Supporting New Language Acquisition Using Brain Signals,” Register Number: 10-2766793 (Korea).
* “Method and apparatus for speech synthesis based on brain signals during imagined speech,” Register Number: 10-2709425 (Korea).
* “Personal authentication apparatus and system based on brain signals of imagined speech,” Register Number: 10-2522391 (Korea).
* “Apparatus and Method for Left- and Right-Foot Classification Based on Brain Signals,” Registration Number: 10-2276991 (Korea).
* “Smart Home Control System and Apparatus based on Brain-Computer Interface Using Minimum Stimulus,” Application Number: 10-2022-0163784 (Korea).
* “A method for user intent recognition through similarity comparison by extracting features from imagined speech and overt speech in brain-computer interface,” Application Number: 10-2022-0163782 (Korea).
* “Brain-Computer Interface System for Supporting New Language Acquisition Using Brain Signals,” Application Number: 10-2022-0173553 (Korea).
* “Bio-signal-based metaverse system implementation method for predicting and reconstructing user's facial emotions and mouth shapes based on bio-signals,” Application Number: 10-2022-0163781 (Korea).
* “Personal authentication apparatus and system based on brain signals of imagined speech,” Application Number: 10-2021-0079992 (Korea).
* “Apparatus and method for left- and right-foot classification based on brain signals,” Application Number: 10-2018-0135194 (Korea).

## Peer Review
* AAAI
* IEEE Transactions on Neural Networks and Learning Systems
* IEEE Transactions on Industrial Informatics
* IEEE Transactions on Instrumentation & Measurement
* Journal of Engineering in Medicine
* Computer Methods and Programs in Biomedicine
* Scientific Data
* Journal of Integrative Neuroscience
* Brain Connectivity
* Measurement Science Review
* IEEE International Conference on Systems, Man, and Cybernetics (SMC)
* IEEE International Winter Conference on Brain-Computer
* International Conference on Multimodal Interaction




고려대학교 뇌공학과 이영은
